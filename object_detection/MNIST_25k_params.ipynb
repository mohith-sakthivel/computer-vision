{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sn_alYjPxVaG"
   },
   "source": [
    "### MNIST Classifer model with  < 25 parameters\n",
    "\n",
    "In this notebook, a conv net is trained on the MNIST dataset. The model is loosely based on **LeNet** with some modern enhancements.\n",
    "\n",
    "The Model has **<25K parameters** and achieves **>99.5% accuracy** on the MNIST test set.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yq2V5wfUH6b6"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jSdV1lkeumb7"
   },
   "outputs": [],
   "source": [
    "def get_size(img_shape, filters):\n",
    "  \"\"\" Calculate the shape of conv net output \"\"\"\n",
    "  out_shape = img_shape[-2:]\n",
    "  for f in filters:\n",
    "    if f[0] == 'pool':\n",
    "      out_shape.div_(f[1])\n",
    "    elif f[0] == 'conv':\n",
    "      k, s, p = f[1:]\n",
    "      out_shape = torch.floor(((out_shape + 2*p - (k-1) - 1)/s)+1)\n",
    "  return out_shape.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iwt7ns7-oTVO"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "  def __init__(self, input_shape, out_dim, fc_layers=[100, 50]):\n",
    "    \n",
    "    super(Model, self).__init__()\n",
    "\n",
    "    # details of the conv net layers\n",
    "    lyrs = [('conv', 5, 1, 0),\n",
    "            ('conv', 5, 1, 0),\n",
    "            ('pool', 2),\n",
    "            ('conv', 3, 1, 0),\n",
    "            ('conv', 3, 1, 0),\n",
    "            ('pool', 2)]\n",
    "\n",
    "    # initialize the conv layers\n",
    "    self.conv_1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0, bias=True)\n",
    "    self.conv_2 = nn.Conv2d(6, 6, kernel_size=5, stride=1, padding=0, bias=False)\n",
    "    self.bn_1 = nn.BatchNorm2d(6, affine=True)\n",
    "    self.conv_3 = nn.Conv2d(6, 16, kernel_size=3, stride=1, padding=0, bias=True)\n",
    "    self.conv_4 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0, bias=False)\n",
    "    self.bn_2 = nn.BatchNorm2d(16, affine=True)\n",
    "\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "    t_out = get_size(torch.tensor(input_shape), lyrs)\n",
    "    # print(f'ConvNet output shape: {t_out[0]}x{t_out[1]}')\n",
    "    self._conv_out_dim = int(np.prod(t_out)*16)\n",
    "\n",
    "    # initialize the fully-connected layers\n",
    "    self._fc = []\n",
    "    inp = self._conv_out_dim\n",
    "\n",
    "    for lyr_dim in fc_layers:\n",
    "      self._fc.append(nn.Linear(inp, lyr_dim, bias=False))\n",
    "      self._fc.append(nn.BatchNorm1d(lyr_dim, affine=True))\n",
    "      self._fc.append(nn.ReLU())\n",
    "      inp = lyr_dim\n",
    "    self._fc.append(nn.Linear(inp, out_dim))\n",
    "    self._fc = nn.Sequential(*self._fc)\n",
    "\n",
    "    self.parameter_count()\n",
    "\n",
    "  def parameter_count(self):\n",
    "    \"\"\" Calculate the number of parameters in the model \"\"\"\n",
    "    num_params=0\n",
    "    for params in self.parameters():\n",
    "      num_params += params.numel()\n",
    "    print(f'Model has {num_params} parameters...')\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.conv_1(x))\n",
    "    x = self.pool(F.relu(self.bn_1(self.conv_2(x))))\n",
    "    x = F.relu(self.conv_3(x))\n",
    "    x = self.pool(F.relu(self.bn_2(self.conv_4(x))))\n",
    "    x = x.view(-1, self._conv_out_dim)\n",
    "    x = self._fc(x)\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "M93Uvd4u6Fn3"
   },
   "outputs": [],
   "source": [
    "# major hyperparameters\n",
    "seed = 0\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 30\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "weight_decay = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RDMiUhcFnVhg"
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DHnRpF7hh9t0"
   },
   "outputs": [],
   "source": [
    "# data preprocessing and augumentation\n",
    "da_transforms = transforms.RandomApply([transforms.RandomAffine(10, scale=(0.95, 1.05), translate=(0.1, 0.1))], p=0.5)\n",
    "\n",
    "train_transform = transforms.Compose([da_transforms,\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, ), (0.5, ))])\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, ), (0.5, ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_QKJreT2j54D"
   },
   "outputs": [],
   "source": [
    "# setup the train/test data loaders\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True,\n",
    "                          download=True, transform=train_transform)\n",
    "testset = datasets.MNIST(root='./data', train=False,\n",
    "                         download=True, transform=test_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Bt16dSHqETL",
    "outputId": "f4f3865a-08d3-492a-bdf5-c74c96206b3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 24494 parameters...\n",
      "Using cuda...\n"
     ]
    }
   ],
   "source": [
    "# setup model, loss, and optimizer\n",
    "\n",
    "network = Model(trainset.data.shape[-3:], len(trainset.classes))\n",
    "network.to(device)\n",
    "print(f'Using {device}...')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.2, last_epoch=-1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KpgJ0LOu-KI-"
   },
   "outputs": [],
   "source": [
    "def train(net, criterion, optimizer, scheduler=None, num_epochs=30, train_set=trainloader, test_set=testloader):\n",
    "  \"\"\"\n",
    "  Trains the provided model for specified number of epochs\n",
    "  \"\"\"\n",
    "  loss_hist = []\n",
    "  time_hist = []\n",
    "\n",
    "  for epoch in range(1, num_epochs+1):\n",
    "    loss_hist.append([])\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i, data in enumerate(train_set, 0):\n",
    "      inputs, labels = data[0].to(device), data[1].to(device)\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      loss_hist[-1].append(loss.cpu().item())\n",
    "    \n",
    "    loss_hist[-1] = np.round(np.mean(loss_hist[-1]), 4)\n",
    "    time_hist.append(np.round(time.time()-start_time, 2))\n",
    "    print(f'Epoch {epoch}  -  loss: {loss_hist[-1]}  time: {time_hist[-1]}')\n",
    "    if (epoch%5) == 0:\n",
    "      print('---------------------------------------')\n",
    "      get_accuracy(network, train_set, label='Train')\n",
    "      get_accuracy(network, test_set, label='Test')\n",
    "      print('---------------------------------------')\n",
    "      network.train()\n",
    "    if scheduler is not None:\n",
    "      scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PfV0KDdeF8lo"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(network, dataloader, label='Test'):\n",
    "  \"\"\" Test the performance of the network on the provided dataset \"\"\"\n",
    "  network.eval()\n",
    "  with torch.no_grad():\n",
    "    c = []\n",
    "    for data in dataloader:\n",
    "      images, labels = data[0].to(device), data[1].to(device)\n",
    "      outputs = network(images)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      c.append((predicted == labels).squeeze())\n",
    "\n",
    "    c = torch.cat(c, dim=0)\n",
    "    acc = 100*(c.sum()/len(c))\n",
    "    print(f'{label} Accuracy: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eCKo5MpJL_m0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  -  loss: 0.3044  time: 19.72\n",
      "Epoch 2  -  loss: 0.1  time: 19.59\n",
      "Epoch 3  -  loss: 0.0811  time: 18.26\n",
      "Epoch 4  -  loss: 0.0769  time: 18.41\n",
      "Epoch 5  -  loss: 0.0699  time: 18.38\n",
      "---------------------------------------\n",
      "Train Accuracy: 98.38%\n",
      "Test Accuracy: 98.92%\n",
      "---------------------------------------\n",
      "Epoch 6  -  loss: 0.0649  time: 17.64\n",
      "Epoch 7  -  loss: 0.0651  time: 17.82\n",
      "Epoch 8  -  loss: 0.0618  time: 17.74\n",
      "Epoch 9  -  loss: 0.0597  time: 17.52\n",
      "Epoch 10  -  loss: 0.0568  time: 17.66\n",
      "---------------------------------------\n",
      "Train Accuracy: 98.62%\n",
      "Test Accuracy: 99.13%\n",
      "---------------------------------------\n",
      "Epoch 11  -  loss: 0.0417  time: 17.9\n",
      "Epoch 12  -  loss: 0.0368  time: 18.12\n",
      "Epoch 13  -  loss: 0.0365  time: 18.53\n",
      "Epoch 14  -  loss: 0.0349  time: 17.93\n",
      "Epoch 15  -  loss: 0.0345  time: 18.08\n",
      "---------------------------------------\n",
      "Train Accuracy: 99.22%\n",
      "Test Accuracy: 99.49%\n",
      "---------------------------------------\n",
      "Epoch 16  -  loss: 0.0345  time: 18.13\n",
      "Epoch 17  -  loss: 0.0346  time: 17.93\n",
      "Epoch 18  -  loss: 0.0327  time: 18.07\n",
      "Epoch 19  -  loss: 0.034  time: 18.01\n",
      "Epoch 20  -  loss: 0.0323  time: 18.25\n",
      "---------------------------------------\n",
      "Train Accuracy: 99.39%\n",
      "Test Accuracy: 99.47%\n",
      "---------------------------------------\n",
      "Epoch 21  -  loss: 0.0292  time: 17.97\n",
      "Epoch 22  -  loss: 0.0279  time: 18.44\n",
      "Epoch 23  -  loss: 0.0273  time: 18.93\n",
      "Epoch 24  -  loss: 0.0272  time: 19.12\n",
      "Epoch 25  -  loss: 0.0258  time: 18.95\n",
      "---------------------------------------\n",
      "Train Accuracy: 99.49%\n",
      "Test Accuracy: 99.53%\n",
      "---------------------------------------\n",
      "Epoch 26  -  loss: 0.0265  time: 18.9\n",
      "Epoch 27  -  loss: 0.026  time: 19.0\n",
      "Epoch 28  -  loss: 0.0262  time: 19.81\n",
      "Epoch 29  -  loss: 0.0247  time: 19.39\n",
      "Epoch 30  -  loss: 0.0256  time: 18.34\n",
      "---------------------------------------\n",
      "Train Accuracy: 99.50%\n",
      "Test Accuracy: 99.59%\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train(network, criterion=criterion, optimizer=optimizer, scheduler=scheduler, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
